{"cells":[{"metadata":{"_uuid":"22f8beb144b6d2a37cb903b11675f0d5c3a5e667"},"cell_type":"markdown","source":"# GANs nÂ´ Roses\n#### by Peterson Katagiri Zilli\n\nI will show how to build and train a simple _Generative Adversarial Networks (GAN)_ and a _Deep Convolutional GAN (DCGAN)_ in a dataset for generating realistic roses images.\n\nSee also:\n* https://medium.com/@jonathan_hui/gan-why-it-is-so-hard-to-train-generative-advisory-networks-819a86b3750b\n* https://github.com/Zackory/Keras-MNIST-GAN/blob/master/mnist_gan.py\n* https://github.com/eriklindernoren/Keras-GAN"},{"metadata":{"_uuid":"123910ba5a50c4e67cebf29e05041aa70912e5f2"},"cell_type":"markdown","source":"## The Data\n\nFirst we configure the paths and get the rose images filenames."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0ebb9d36b6d5ee5d97e0478a9fc0ad4acfe717c0"},"cell_type":"code","source":"import numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1354eb035ee54f0ea2eed1542137bf0fb8709841","collapsed":true},"cell_type":"code","source":"import os\nfrom glob import glob\nimport cv2\n\nfrom keras.layers import Input, Dense, Reshape, Flatten, Dropout\nfrom keras.layers import BatchNormalization, Activation, ZeroPadding2D, UpSampling2D, Conv2D\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam\n\n%matplotlib inline\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"#PATH = os.path.abspath(os.path.join('..','input', 'flowers', 'flowers', 'rose'))\nPATH = os.path.abspath(os.path.join('..','input', 'roseimages', 'roseimages'))\nIMGS = glob(os.path.join(PATH, \"*.jpg\"))\n\nprint(len(IMGS)) # number of the rose images\nprint(IMGS[:10]) # rose images filenames","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d171a91df1928ddde364d7cda854629904dbc72"},"cell_type":"markdown","source":"Then we resize the images to WIDTH pixels width, HEIGHT pixels height, and DEPTH color channels)"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"WIDTH = 28\nHEIGHT = 28\nDEPTH = 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4cbd7c8e737a1ecbd50aab6100dee71e05cd7967","collapsed":true},"cell_type":"code","source":"def procImages(images):\n    processed_images = []\n    \n    # set depth\n    depth = None\n    if DEPTH == 1:\n        depth = cv2.IMREAD_GRAYSCALE\n    elif DEPTH == 3:\n        depth = cv2.IMREAD_COLOR\n    else:\n        print('DEPTH must be set to 1 or to 3.')\n        return None\n    \n    #resize images\n    for img in images:\n        base = os.path.basename(img)\n        full_size_image = cv2.imread(img, depth)\n        processed_images.append(cv2.resize(full_size_image, (WIDTH, HEIGHT), interpolation=cv2.INTER_CUBIC))\n    processed_images = np.asarray(processed_images)\n    \n    # rescale images to [-1, 1]\n    processed_images = np.divide(processed_images, 127.5) - 1\n\n    return processed_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"db3c208063517bdba8cb580e6b9177cd36d56620","collapsed":true},"cell_type":"code","source":"processed_images = procImages(IMGS)\nprocessed_images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f75fc1cc0499f6651724ea76c87526f23bcb5d3","collapsed":true},"cell_type":"code","source":"fig, axs = plt.subplots(5, 5)\ncount = 0\nfor i in range(5):\n    for j in range(5):\n        img = processed_images[count, :, :, :] * 127.5 + 127.5\n        img = np.asarray(img, dtype=np.uint8)\n        if DEPTH == 3:\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        axs[i, j].imshow(img)\n        axs[i, j].axis('off')\n        count += 1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"47af6c721002ac21c40c2fb6a6fa46b519522f1d"},"cell_type":"markdown","source":"## Building Simple GAN Model"},{"metadata":{"_uuid":"a9388667bd2d9c60db9fb14467597aa6ad4b59d4"},"cell_type":"markdown","source":"Below we create functions for building simple dense generator and a discriminator modelsa"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"867cb8f54520c216f445aaff9e27131c5da04fcc"},"cell_type":"code","source":"# GAN parameters\nLATENT_DIM = 100\nG_LAYERS_DIM = [256, 512, 1024]\nD_LAYERS_DIM = [1024, 512, 256]\n\nBATCH_SIZE = 16\nEPOCHS = 1000\nLR = 0.0002\nBETA_1 = 0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"42e67bbdc98d991242de8da8a4161d255bab2a28"},"cell_type":"code","source":"def buildGenerator(img_shape):\n\n    def addLayer(model, dim):\n        model.add(Dense(dim))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        \n    model = Sequential()\n    model.add(Dense(G_LAYERS_DIM[0], input_dim=LATENT_DIM))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(BatchNormalization(momentum=0.8))\n    \n    for layer_dim in G_LAYERS_DIM[1:]:\n        addLayer(model, layer_dim)\n        \n    model.add(Dense(np.prod(img_shape), activation='tanh'))\n    model.add(Reshape(img_shape))\n\n    model.summary()\n\n    noise = Input(shape=(LATENT_DIM,))\n    img = model(noise)\n\n    return Model(noise, img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfc5ce0f910e25084ff75207ab29b636d070dc4f","collapsed":true},"cell_type":"code","source":"#g = buildGenerator(processed_images.shape[1:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c85ad45293a8209d27780762e6052c4534e2c48b"},"cell_type":"code","source":"def buildDiscriminator(img_shape):\n\n    def addLayer(model, dim):\n        model.add(Dense(dim))\n        model.add(LeakyReLU(alpha=0.2))\n\n    model = Sequential()\n    model.add(Flatten(input_shape=img_shape))\n    \n    for layer_dim in D_LAYERS_DIM:\n        addLayer(model, layer_dim)\n        \n    model.add(Dense(1, activation='sigmoid'))\n    model.summary()\n\n    img = Input(shape=img_shape)\n    classification = model(img)\n\n    return Model(img, classification)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3d9c4272646972e4e206a07876ce6038471d79e","collapsed":true},"cell_type":"code","source":"#d = buildDiscriminator(processed_images.shape[1:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8120689803c63c0fb6972d4b6cecaf2e2fcc0cdf"},"cell_type":"code","source":"def buildCombined(g, d):\n    # fix d for training g in the combined model\n    d.trainable = False\n\n    # g gets z as input and outputs fake_img\n    z = Input(shape=(LATENT_DIM,))\n    fake_img = g(z)\n\n    # gets the classification of the fake image\n    gan_output = d(fake_img)\n\n    # the combined model for training generator g to fool discriminator d\n    model = Model(z, gan_output)\n    model.summary()\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d40801e20530ca2b843ba1eadd019c90fb7711a","collapsed":true},"cell_type":"code","source":"def sampleImages(generator):\n    rows, columns = 5, 5\n    noise = np.random.normal(0, 1, (rows * columns, LATENT_DIM))\n    generated_imgs = generator.predict(noise)\n\n    fig, axs = plt.subplots(rows, columns)\n    count = 0\n    for i in range(rows):\n        for j in range(columns):\n            img = generated_imgs[count, :, :, :] * 127.5 + 127.5\n            img = np.asarray(img, dtype=np.uint8)\n            if DEPTH == 3:\n                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            axs[i, j].imshow(img)\n            axs[i, j].axis('off')\n            count += 1\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ace8b79fea796f61db11fdb3f652d73daf9c2630","collapsed":true},"cell_type":"code","source":"#sampleImages(g)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"60d002b150caa089b723e4428799afdcbde5e6d4"},"cell_type":"code","source":"#instantiate the optimizer\noptimizer = Adam(LR, BETA_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"79ba906c8a2b6d4bfa699941adbdda9e95ae3756","collapsed":true},"cell_type":"code","source":"#build the discriminator\nd = buildDiscriminator(processed_images.shape[1:])\nd.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18b5cf7e7c8b7653e25ec95c3061c26703dda191","collapsed":true},"cell_type":"code","source":"#build generator\ng = buildGenerator(processed_images.shape[1:])\ng.compile(loss='binary_crossentropy', optimizer=optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"551bb46f09d5056b6ec2672a70aaf7b386ebd8b7","collapsed":true},"cell_type":"code","source":"#build combined model\nc = buildCombined(g, d)\nc.compile(loss='binary_crossentropy', optimizer=optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"ad0b2532c9d792effed596fc046993d70143ba8b","collapsed":true},"cell_type":"code","source":"#training\nSAMPLE_INTERVAL = WARNING_INTERVAL = 100\n\nYDis = np.zeros(2 * BATCH_SIZE)\nYDis[:BATCH_SIZE] = .9 #Label smoothing\n\nYGen = np.ones(BATCH_SIZE)\n\nfor epoch in range(EPOCHS):\n    # get a batch of real images\n    idx = np.random.randint(0, processed_images.shape[0], BATCH_SIZE)\n    real_imgs = processed_images[idx]\n\n    # generate a batch of fake images\n    noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))\n    fake_imgs = g.predict(noise)\n    \n    X = np.concatenate([real_imgs, fake_imgs])\n    \n    # Train discriminator\n    d.trainable = True\n    d_loss = d.train_on_batch(X, YDis)\n\n    # Train the generator\n    d.trainable = False\n    #noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))\n    g_loss = c.train_on_batch(noise, YGen)\n\n    # Progress\n    if (epoch+1) % WARNING_INTERVAL == 0 or epoch == 0:\n        print (\"%d [Discriminator Loss: %f, Acc.: %.2f%%] [Generator Loss: %f]\" % (epoch, d_loss[0], 100. * d_loss[1], g_loss))\n\n    # If at save interval => save generated image samples\n    if (epoch+1) % SAMPLE_INTERVAL == 0 or epoch == 0:\n        sampleImages(g)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"42ce022899af0c307804b8ff1299cd032ecd287c"},"cell_type":"markdown","source":"## Building Deep Convolutional GAN Model"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fe9f0e2954bf2669180ccabe6005c2263027ac85"},"cell_type":"code","source":"def buildGeneratorDC(img_shape):\n    model = Sequential()\n\n    model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=LATENT_DIM))\n    model.add(Reshape((7, 7, 128)))\n    model.add(UpSampling2D())\n    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n    model.add(UpSampling2D())\n    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n    model.add(Conv2D(DEPTH, kernel_size=3, padding=\"same\"))\n    model.add(Activation(\"tanh\"))\n\n    model.summary()\n\n    noise = Input(shape=(LATENT_DIM,))\n    img = model(noise)\n\n    return Model(noise, img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"592aa07132a5e9a4d0e133d74b5d4782dd359621"},"cell_type":"code","source":"def buildDiscriminatorDC(img_shape):\n    model = Sequential()\n\n    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    \n    model.add(Dropout(0.25))\n    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    \n    model.add(Dropout(0.25))\n    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    \n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(1, activation='sigmoid'))\n\n    model.summary()\n\n    img = Input(shape=img_shape)\n    classification = model(img)\n\n    return Model(img, classification)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"47213b3243b53e24f82380beccedf78e900fac98","collapsed":true},"cell_type":"code","source":"#build the discriminator\ndDC = buildDiscriminatorDC(processed_images.shape[1:])\ndDC.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"113881959b886063955fd9bf887d8d0b6223755d","collapsed":true},"cell_type":"code","source":"#build generator\ngDC = buildGeneratorDC(processed_images.shape[1:])\ngDC.compile(loss='binary_crossentropy', optimizer=optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be94d2703a66f1bab208d328cad4d7a188e5e6a1","collapsed":true},"cell_type":"code","source":"#build combined model\ncDC = buildCombined(gDC, dDC)\ncDC.compile(loss='binary_crossentropy', optimizer=optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"5a23a01dd90a903f0f53cb474e43cbfa1bf73b40","collapsed":true},"cell_type":"code","source":"#training DC GAN\nSAMPLE_INTERVAL = WARNING_INTERVAL = 100\n\nYDis = np.zeros(2 * BATCH_SIZE)\nYDis[:BATCH_SIZE] = .9 #Label smoothing\n\nYGen = np.ones(BATCH_SIZE)\n\nfor epoch in range(EPOCHS):\n    # get a batch of real images\n    idx = np.random.randint(0, processed_images.shape[0], BATCH_SIZE)\n    real_imgs = processed_images[idx]\n\n    # generate a batch of fake images\n    noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))\n    fake_imgs = gDC.predict(noise)\n    \n    X = np.concatenate([real_imgs, fake_imgs])\n    \n    # Train discriminator\n    dDC.trainable = True\n    d_loss = dDC.train_on_batch(X, YDis)\n\n    # Train the generator\n    dDC.trainable = False\n    #noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))\n    g_loss = cDC.train_on_batch(noise, YGen)\n\n    # Progress\n    if (epoch+1) % WARNING_INTERVAL == 0 or epoch == 0:\n        print (\"%d [Discriminator Loss: %f, Acc.: %.2f%%] [Generator Loss: %f]\" % (epoch, d_loss[0], 100. * d_loss[1], g_loss))\n\n    # If at save interval => save generated image samples\n    if (epoch+1) % SAMPLE_INTERVAL == 0 or epoch == 0:\n        sampleImages(gDC)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c326006285ffd333be79d7c2477b75d97c3586a7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a067e7ff3cac4201e42b32ec53981e3679658264"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}